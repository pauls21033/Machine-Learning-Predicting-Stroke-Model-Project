{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca0fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 20:04:51.782333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4691d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>nhiss</th>\n",
       "      <th>severity_level</th>\n",
       "      <th>mrs</th>\n",
       "      <th>systolic</th>\n",
       "      <th>distolic</th>\n",
       "      <th>glucose</th>\n",
       "      <th>paralysis</th>\n",
       "      <th>smoking</th>\n",
       "      <th>bmi</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>tos</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>89</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>116</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  nhiss  severity_level  mrs  systolic  distolic  glucose  \\\n",
       "0   75       1      4               1    1       140        89      190   \n",
       "1   68       1      1               1    1       133       116      174   \n",
       "2   88       0      1               1    1       124       118       79   \n",
       "3   58       0      4               1    0       126       105      198   \n",
       "4   50       1      3               1    2       140       106       87   \n",
       "\n",
       "   paralysis  smoking  bmi  cholestrol  tos  risk  \n",
       "0          1        1   25         205    1     1  \n",
       "1          1        0   35         206    1     1  \n",
       "2          2        0   35         239    1     1  \n",
       "3          0        0   25         222    1     1  \n",
       "4          0        0   39         222    1     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Dataset:\n",
    "dataset = pd.read_csv(\"Resources/Prepped_Stroke_Data.csv\")\n",
    "# Top 5 records:\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12042915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>nhiss</th>\n",
       "      <th>severity_level</th>\n",
       "      <th>mrs</th>\n",
       "      <th>systolic</th>\n",
       "      <th>distolic</th>\n",
       "      <th>glucose</th>\n",
       "      <th>paralysis</th>\n",
       "      <th>smoking</th>\n",
       "      <th>bmi</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>tos</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033676</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.439812</td>\n",
       "      <td>0.476497</td>\n",
       "      <td>-0.050585</td>\n",
       "      <td>0.089203</td>\n",
       "      <td>0.320757</td>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.471120</td>\n",
       "      <td>-0.013581</td>\n",
       "      <td>0.122307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-0.033676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.171225</td>\n",
       "      <td>-0.147354</td>\n",
       "      <td>-0.098114</td>\n",
       "      <td>-0.078162</td>\n",
       "      <td>-0.073362</td>\n",
       "      <td>-0.044245</td>\n",
       "      <td>-0.041195</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>-0.086824</td>\n",
       "      <td>-0.095736</td>\n",
       "      <td>-0.092974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nhiss</th>\n",
       "      <td>0.058495</td>\n",
       "      <td>-0.171225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930975</td>\n",
       "      <td>0.695623</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>0.254689</td>\n",
       "      <td>0.437065</td>\n",
       "      <td>0.195058</td>\n",
       "      <td>0.101446</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.223306</td>\n",
       "      <td>0.534138</td>\n",
       "      <td>0.557640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severity_level</th>\n",
       "      <td>0.033389</td>\n",
       "      <td>-0.147354</td>\n",
       "      <td>0.930975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767575</td>\n",
       "      <td>0.388640</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.518909</td>\n",
       "      <td>0.201266</td>\n",
       "      <td>0.086293</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.187086</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.607909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <td>0.041504</td>\n",
       "      <td>-0.098114</td>\n",
       "      <td>0.695623</td>\n",
       "      <td>0.767575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377404</td>\n",
       "      <td>0.218693</td>\n",
       "      <td>0.544069</td>\n",
       "      <td>0.190380</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>0.167718</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.521503</td>\n",
       "      <td>0.556399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systolic</th>\n",
       "      <td>0.439812</td>\n",
       "      <td>-0.078162</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>0.388640</td>\n",
       "      <td>0.377404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590822</td>\n",
       "      <td>0.299251</td>\n",
       "      <td>0.190716</td>\n",
       "      <td>0.226261</td>\n",
       "      <td>0.118996</td>\n",
       "      <td>0.531017</td>\n",
       "      <td>0.284736</td>\n",
       "      <td>0.412328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distolic</th>\n",
       "      <td>0.476497</td>\n",
       "      <td>-0.073362</td>\n",
       "      <td>0.254689</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.218693</td>\n",
       "      <td>0.590822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>0.179014</td>\n",
       "      <td>0.279731</td>\n",
       "      <td>0.111874</td>\n",
       "      <td>0.541236</td>\n",
       "      <td>0.184149</td>\n",
       "      <td>0.288969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>-0.050585</td>\n",
       "      <td>-0.044245</td>\n",
       "      <td>0.437065</td>\n",
       "      <td>0.518909</td>\n",
       "      <td>0.544069</td>\n",
       "      <td>0.299251</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>-0.047011</td>\n",
       "      <td>0.120565</td>\n",
       "      <td>0.104890</td>\n",
       "      <td>0.368605</td>\n",
       "      <td>0.502262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paralysis</th>\n",
       "      <td>0.089203</td>\n",
       "      <td>-0.041195</td>\n",
       "      <td>0.195058</td>\n",
       "      <td>0.201266</td>\n",
       "      <td>0.190380</td>\n",
       "      <td>0.190716</td>\n",
       "      <td>0.179014</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>0.107851</td>\n",
       "      <td>0.157792</td>\n",
       "      <td>0.116854</td>\n",
       "      <td>0.258843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking</th>\n",
       "      <td>0.320757</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.101446</td>\n",
       "      <td>0.086293</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>0.226261</td>\n",
       "      <td>0.279731</td>\n",
       "      <td>-0.047011</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.280354</td>\n",
       "      <td>0.063322</td>\n",
       "      <td>0.177899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.015409</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.167718</td>\n",
       "      <td>0.118996</td>\n",
       "      <td>0.111874</td>\n",
       "      <td>0.120565</td>\n",
       "      <td>0.107851</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.124956</td>\n",
       "      <td>0.239716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cholestrol</th>\n",
       "      <td>0.471120</td>\n",
       "      <td>-0.086824</td>\n",
       "      <td>0.223306</td>\n",
       "      <td>0.187086</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.531017</td>\n",
       "      <td>0.541236</td>\n",
       "      <td>0.104890</td>\n",
       "      <td>0.157792</td>\n",
       "      <td>0.280354</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.256448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tos</th>\n",
       "      <td>-0.013581</td>\n",
       "      <td>-0.095736</td>\n",
       "      <td>0.534138</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.521503</td>\n",
       "      <td>0.284736</td>\n",
       "      <td>0.184149</td>\n",
       "      <td>0.368605</td>\n",
       "      <td>0.116854</td>\n",
       "      <td>0.063322</td>\n",
       "      <td>0.124956</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk</th>\n",
       "      <td>0.122307</td>\n",
       "      <td>-0.092974</td>\n",
       "      <td>0.557640</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.556399</td>\n",
       "      <td>0.412328</td>\n",
       "      <td>0.288969</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>0.258843</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.239716</td>\n",
       "      <td>0.256448</td>\n",
       "      <td>0.506828</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age    gender     nhiss  severity_level       mrs  \\\n",
       "age             1.000000 -0.033676  0.058495        0.033389  0.041504   \n",
       "gender         -0.033676  1.000000 -0.171225       -0.147354 -0.098114   \n",
       "nhiss           0.058495 -0.171225  1.000000        0.930975  0.695623   \n",
       "severity_level  0.033389 -0.147354  0.930975        1.000000  0.767575   \n",
       "mrs             0.041504 -0.098114  0.695623        0.767575  1.000000   \n",
       "systolic        0.439812 -0.078162  0.369223        0.388640  0.377404   \n",
       "distolic        0.476497 -0.073362  0.254689        0.239997  0.218693   \n",
       "glucose        -0.050585 -0.044245  0.437065        0.518909  0.544069   \n",
       "paralysis       0.089203 -0.041195  0.195058        0.201266  0.190380   \n",
       "smoking         0.320757 -0.056915  0.101446        0.086293  0.044584   \n",
       "bmi             0.015409 -0.022629  0.145126        0.140277  0.167718   \n",
       "cholestrol      0.471120 -0.086824  0.223306        0.187086  0.164646   \n",
       "tos            -0.013581 -0.095736  0.534138        0.581724  0.521503   \n",
       "risk            0.122307 -0.092974  0.557640        0.607909  0.556399   \n",
       "\n",
       "                systolic  distolic   glucose  paralysis   smoking       bmi  \\\n",
       "age             0.439812  0.476497 -0.050585   0.089203  0.320757  0.015409   \n",
       "gender         -0.078162 -0.073362 -0.044245  -0.041195 -0.056915 -0.022629   \n",
       "nhiss           0.369223  0.254689  0.437065   0.195058  0.101446  0.145126   \n",
       "severity_level  0.388640  0.239997  0.518909   0.201266  0.086293  0.140277   \n",
       "mrs             0.377404  0.218693  0.544069   0.190380  0.044584  0.167718   \n",
       "systolic        1.000000  0.590822  0.299251   0.190716  0.226261  0.118996   \n",
       "distolic        0.590822  1.000000  0.151600   0.179014  0.279731  0.111874   \n",
       "glucose         0.299251  0.151600  1.000000   0.164600 -0.047011  0.120565   \n",
       "paralysis       0.190716  0.179014  0.164600   1.000000  0.059543  0.107851   \n",
       "smoking         0.226261  0.279731 -0.047011   0.059543  1.000000  0.006805   \n",
       "bmi             0.118996  0.111874  0.120565   0.107851  0.006805  1.000000   \n",
       "cholestrol      0.531017  0.541236  0.104890   0.157792  0.280354  0.073444   \n",
       "tos             0.284736  0.184149  0.368605   0.116854  0.063322  0.124956   \n",
       "risk            0.412328  0.288969  0.502262   0.258843  0.177899  0.239716   \n",
       "\n",
       "                cholestrol       tos      risk  \n",
       "age               0.471120 -0.013581  0.122307  \n",
       "gender           -0.086824 -0.095736 -0.092974  \n",
       "nhiss             0.223306  0.534138  0.557640  \n",
       "severity_level    0.187086  0.581724  0.607909  \n",
       "mrs               0.164646  0.521503  0.556399  \n",
       "systolic          0.531017  0.284736  0.412328  \n",
       "distolic          0.541236  0.184149  0.288969  \n",
       "glucose           0.104890  0.368605  0.502262  \n",
       "paralysis         0.157792  0.116854  0.258843  \n",
       "smoking           0.280354  0.063322  0.177899  \n",
       "bmi               0.073444  0.124956  0.239716  \n",
       "cholestrol        1.000000  0.110074  0.256448  \n",
       "tos               0.110074  1.000000  0.506828  \n",
       "risk              0.256448  0.506828  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a524529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>systolic</th>\n",
       "      <th>distolic</th>\n",
       "      <th>glucose</th>\n",
       "      <th>paralysis</th>\n",
       "      <th>smoking</th>\n",
       "      <th>bmi</th>\n",
       "      <th>cholestrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>89</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>116</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>83</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>88</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>111</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>82</td>\n",
       "      <td>262</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>115</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4550 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  systolic  distolic  glucose  paralysis  smoking  bmi  \\\n",
       "0      75       1       140        89      190          1        1   25   \n",
       "1      68       1       133       116      174          1        0   35   \n",
       "2      88       0       124       118       79          2        0   35   \n",
       "3      58       0       126       105      198          0        0   25   \n",
       "4      50       1       140       106       87          0        0   39   \n",
       "...   ...     ...       ...       ...      ...        ...      ...  ...   \n",
       "4545   67       0       180        83      198          1        2   39   \n",
       "4546   67       1       180        88      188          0        2   22   \n",
       "4547   65       0       126       111      227          0        3   23   \n",
       "4548   64       0       126        82      262          2        2   28   \n",
       "4549   65       0       169       115      263          0        3   27   \n",
       "\n",
       "      cholestrol  \n",
       "0            205  \n",
       "1            206  \n",
       "2            239  \n",
       "3            222  \n",
       "4            222  \n",
       "...          ...  \n",
       "4545         219  \n",
       "4546         187  \n",
       "4547         233  \n",
       "4548         244  \n",
       "4549         231  \n",
       "\n",
       "[4550 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop([\"nhiss\",\"severity_level\",\"mrs\",\"tos\", \"risk\"],axis=1)\n",
    "y = dataset[\"severity_level\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964fb433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mild_to_moderate</th>\n",
       "      <th>severe</th>\n",
       "      <th>very_severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4550 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mild_to_moderate  severe  very_severe\n",
       "0                    0       0            0\n",
       "1                    0       0            0\n",
       "2                    0       0            0\n",
       "3                    0       0            0\n",
       "4                    0       0            0\n",
       "...                ...     ...          ...\n",
       "4545                 1       0            0\n",
       "4546                 0       1            0\n",
       "4547                 1       0            0\n",
       "4548                 0       1            0\n",
       "4549                 1       0            0\n",
       "\n",
       "[4550 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_adjusted = pd.get_dummies(y.replace(1,\"mild\").replace(2,\"mild_to_moderate\").replace(3,\"severe\").replace(4,\"very_severe\"),drop_first=True)\n",
    "y_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "269a0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_adjusted, random_state=98)\n",
    "\n",
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86575f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 20:06:00.779183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 3ms/step - loss: 0.6817 - accuracy: 0.4188\n",
      "Epoch 2/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.4431\n",
      "Epoch 3/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.4698\n",
      "Epoch 4/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.4936\n",
      "Epoch 5/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.5319\n",
      "Epoch 6/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.5437 - accuracy: 0.5569\n",
      "Epoch 7/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.5376 - accuracy: 0.5689\n",
      "Epoch 8/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.5739\n",
      "Epoch 9/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.5809\n",
      "Epoch 10/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.5835\n",
      "Epoch 11/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.5856\n",
      "Epoch 12/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.5900\n",
      "Epoch 13/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.6249\n",
      "Epoch 14/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.6284\n",
      "Epoch 15/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.6334\n",
      "Epoch 16/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.6348\n",
      "Epoch 17/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.6334\n",
      "Epoch 18/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.6319\n",
      "Epoch 19/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.6351\n",
      "Epoch 20/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.6369\n",
      "Epoch 21/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.6354\n",
      "Epoch 22/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.5017 - accuracy: 0.6377\n",
      "Epoch 23/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.5006 - accuracy: 0.6392\n",
      "Epoch 24/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4996 - accuracy: 0.6413\n",
      "Epoch 25/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.6460\n",
      "Epoch 26/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.6436\n",
      "Epoch 27/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.6480\n",
      "Epoch 28/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.6504\n",
      "Epoch 29/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.6527\n",
      "Epoch 30/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.6568\n",
      "Epoch 31/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.6545\n",
      "Epoch 32/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.6594\n",
      "Epoch 33/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.6571\n",
      "Epoch 34/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.6547\n",
      "Epoch 35/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.6568\n",
      "Epoch 36/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.6571\n",
      "Epoch 37/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.6580\n",
      "Epoch 38/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.6612\n",
      "Epoch 39/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.6568\n",
      "Epoch 40/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.6586\n",
      "Epoch 41/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.6594\n",
      "Epoch 42/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.6600\n",
      "Epoch 43/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4804 - accuracy: 0.6571\n",
      "Epoch 44/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.6571\n",
      "Epoch 45/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.6556\n",
      "Epoch 46/400\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 0.4780 - accuracy: 0.6612\n",
      "Epoch 47/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.6577\n",
      "Epoch 48/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.6618\n",
      "Epoch 49/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4764 - accuracy: 0.6550\n",
      "Epoch 50/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.6606\n",
      "Epoch 51/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.6600\n",
      "Epoch 52/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.6603\n",
      "Epoch 53/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.6615\n",
      "Epoch 54/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.6586\n",
      "Epoch 55/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.6615\n",
      "Epoch 56/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.6606\n",
      "Epoch 57/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.6618\n",
      "Epoch 58/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.6603\n",
      "Epoch 59/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.6653\n",
      "Epoch 60/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.6647\n",
      "Epoch 61/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.6594\n",
      "Epoch 62/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.6688\n",
      "Epoch 63/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.6644\n",
      "Epoch 64/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.6624\n",
      "Epoch 65/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.6594\n",
      "Epoch 66/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.6668\n",
      "Epoch 67/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.6627\n",
      "Epoch 68/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.6594\n",
      "Epoch 69/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4668 - accuracy: 0.6624\n",
      "Epoch 70/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.6600\n",
      "Epoch 71/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.6644\n",
      "Epoch 72/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.6632\n",
      "Epoch 73/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.6641\n",
      "Epoch 74/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.6618\n",
      "Epoch 75/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.6615\n",
      "Epoch 76/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.6679\n",
      "Epoch 77/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.6650\n",
      "Epoch 78/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.6618\n",
      "Epoch 79/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.6638\n",
      "Epoch 80/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.6627\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.6668\n",
      "Epoch 82/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.6621\n",
      "Epoch 83/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.6668\n",
      "Epoch 84/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.6653\n",
      "Epoch 85/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.6615\n",
      "Epoch 86/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.6647\n",
      "Epoch 87/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.6635\n",
      "Epoch 88/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.6641\n",
      "Epoch 89/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.6630\n",
      "Epoch 90/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.6662\n",
      "Epoch 91/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.6618\n",
      "Epoch 92/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.6600\n",
      "Epoch 93/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4609 - accuracy: 0.6635\n",
      "Epoch 94/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4607 - accuracy: 0.6589\n",
      "Epoch 95/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4611 - accuracy: 0.6659\n",
      "Epoch 96/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.6618\n",
      "Epoch 97/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.6606\n",
      "Epoch 98/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.6644\n",
      "Epoch 99/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.6635\n",
      "Epoch 100/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.6638\n",
      "Epoch 101/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.6618\n",
      "Epoch 102/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.6644\n",
      "Epoch 103/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.6606\n",
      "Epoch 104/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.6635\n",
      "Epoch 105/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.6632\n",
      "Epoch 106/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.6632\n",
      "Epoch 107/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.6624\n",
      "Epoch 108/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.6635\n",
      "Epoch 109/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.6618\n",
      "Epoch 110/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.6630\n",
      "Epoch 111/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.6641\n",
      "Epoch 112/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.6606\n",
      "Epoch 113/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.6668\n",
      "Epoch 114/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.6635\n",
      "Epoch 115/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.6650\n",
      "Epoch 116/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.6627\n",
      "Epoch 117/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.6630\n",
      "Epoch 118/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.6647\n",
      "Epoch 119/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.6653\n",
      "Epoch 120/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.6630\n",
      "Epoch 121/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.6662\n",
      "Epoch 122/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.6627\n",
      "Epoch 123/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.6644\n",
      "Epoch 124/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.6638\n",
      "Epoch 125/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.6668\n",
      "Epoch 126/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.6647\n",
      "Epoch 127/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.6615\n",
      "Epoch 128/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.6668\n",
      "Epoch 129/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.6627\n",
      "Epoch 130/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.6632\n",
      "Epoch 131/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.6641\n",
      "Epoch 132/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.6647\n",
      "Epoch 133/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.6603\n",
      "Epoch 134/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.6650\n",
      "Epoch 135/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.6615\n",
      "Epoch 136/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.6621\n",
      "Epoch 137/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.6656\n",
      "Epoch 138/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.6615\n",
      "Epoch 139/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.6635\n",
      "Epoch 140/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.6662\n",
      "Epoch 141/400\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.6638\n",
      "Epoch 142/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.6632\n",
      "Epoch 143/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.6682\n",
      "Epoch 144/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.6635\n",
      "Epoch 145/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.6630\n",
      "Epoch 146/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4531 - accuracy: 0.6641\n",
      "Epoch 147/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.6676\n",
      "Epoch 148/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.6653\n",
      "Epoch 149/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4526 - accuracy: 0.6656\n",
      "Epoch 150/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.6656\n",
      "Epoch 151/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4525 - accuracy: 0.6653\n",
      "Epoch 152/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.6668\n",
      "Epoch 153/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.6632\n",
      "Epoch 154/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4519 - accuracy: 0.6662\n",
      "Epoch 155/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.6676\n",
      "Epoch 156/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4520 - accuracy: 0.6665\n",
      "Epoch 157/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6688\n",
      "Epoch 158/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.6653\n",
      "Epoch 159/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.6662\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.6653\n",
      "Epoch 161/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.6700\n",
      "Epoch 162/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.6694\n",
      "Epoch 163/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.6671\n",
      "Epoch 164/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.6682\n",
      "Epoch 165/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.6671\n",
      "Epoch 166/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.6665\n",
      "Epoch 167/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.6691\n",
      "Epoch 168/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.6706\n",
      "Epoch 169/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6709\n",
      "Epoch 170/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.6676\n",
      "Epoch 171/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.6694\n",
      "Epoch 172/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6694\n",
      "Epoch 173/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.6717\n",
      "Epoch 174/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.6674\n",
      "Epoch 175/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.6682\n",
      "Epoch 176/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6682\n",
      "Epoch 177/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.6729\n",
      "Epoch 178/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.6668\n",
      "Epoch 179/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6668\n",
      "Epoch 180/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6703\n",
      "Epoch 181/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.6662\n",
      "Epoch 182/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.6665\n",
      "Epoch 183/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6665\n",
      "Epoch 184/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.6671\n",
      "Epoch 185/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.6662\n",
      "Epoch 186/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6665\n",
      "Epoch 187/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.6653\n",
      "Epoch 188/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.6688\n",
      "Epoch 189/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.6650\n",
      "Epoch 190/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.6674\n",
      "Epoch 191/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.6659\n",
      "Epoch 192/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.6691\n",
      "Epoch 193/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.6650\n",
      "Epoch 194/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.6668\n",
      "Epoch 195/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.6650\n",
      "Epoch 196/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.6694\n",
      "Epoch 197/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.6665\n",
      "Epoch 198/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.6665\n",
      "Epoch 199/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.6641\n",
      "Epoch 200/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.6668\n",
      "Epoch 201/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.6659\n",
      "Epoch 202/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.6679\n",
      "Epoch 203/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.6653\n",
      "Epoch 204/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.6685\n",
      "Epoch 205/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6618\n",
      "Epoch 206/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.6668\n",
      "Epoch 207/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.6624\n",
      "Epoch 208/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.6676\n",
      "Epoch 209/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.6685\n",
      "Epoch 210/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.6638\n",
      "Epoch 211/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6676\n",
      "Epoch 212/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.6638\n",
      "Epoch 213/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.6659\n",
      "Epoch 214/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.6679\n",
      "Epoch 215/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.6650\n",
      "Epoch 216/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.6647\n",
      "Epoch 217/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4462 - accuracy: 0.6630\n",
      "Epoch 218/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.6665\n",
      "Epoch 219/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.6644\n",
      "Epoch 220/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.6656\n",
      "Epoch 221/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6656\n",
      "Epoch 222/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.6676\n",
      "Epoch 223/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.6656\n",
      "Epoch 224/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.6720\n",
      "Epoch 225/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.6659\n",
      "Epoch 226/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.6688\n",
      "Epoch 227/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.6656\n",
      "Epoch 228/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.6688\n",
      "Epoch 229/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.6676\n",
      "Epoch 230/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.6638\n",
      "Epoch 231/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.6700\n",
      "Epoch 232/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.6671\n",
      "Epoch 233/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.6656\n",
      "Epoch 234/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.6671\n",
      "Epoch 235/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.6697\n",
      "Epoch 236/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.6668\n",
      "Epoch 237/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.6641\n",
      "Epoch 238/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.6656\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.6650\n",
      "Epoch 240/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.6659\n",
      "Epoch 241/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.6659\n",
      "Epoch 242/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.6697\n",
      "Epoch 243/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.6653\n",
      "Epoch 244/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.6653\n",
      "Epoch 245/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.6668\n",
      "Epoch 246/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.6665\n",
      "Epoch 247/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6671\n",
      "Epoch 248/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.6697\n",
      "Epoch 249/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.6656\n",
      "Epoch 250/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.6647\n",
      "Epoch 251/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.6650\n",
      "Epoch 252/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.6665\n",
      "Epoch 253/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.6656\n",
      "Epoch 254/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.6697\n",
      "Epoch 255/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.6659\n",
      "Epoch 256/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.6653\n",
      "Epoch 257/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.6691\n",
      "Epoch 258/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.6662\n",
      "Epoch 259/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.6650\n",
      "Epoch 260/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.6688\n",
      "Epoch 261/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6653\n",
      "Epoch 262/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.6647\n",
      "Epoch 263/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.6726\n",
      "Epoch 264/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.6650\n",
      "Epoch 265/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.6691\n",
      "Epoch 266/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.6674\n",
      "Epoch 267/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6688\n",
      "Epoch 268/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.6685\n",
      "Epoch 269/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6656\n",
      "Epoch 270/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.6703\n",
      "Epoch 271/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6656\n",
      "Epoch 272/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.6700\n",
      "Epoch 273/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6712\n",
      "Epoch 274/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.6656\n",
      "Epoch 275/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6685\n",
      "Epoch 276/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6659\n",
      "Epoch 277/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.6709\n",
      "Epoch 278/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6668\n",
      "Epoch 279/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.6715\n",
      "Epoch 280/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.6653\n",
      "Epoch 281/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.6682\n",
      "Epoch 282/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6674\n",
      "Epoch 283/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.6668\n",
      "Epoch 284/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.6709\n",
      "Epoch 285/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.6650\n",
      "Epoch 286/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.6706\n",
      "Epoch 287/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.6665\n",
      "Epoch 288/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.6688\n",
      "Epoch 289/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.6682\n",
      "Epoch 290/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.6682\n",
      "Epoch 291/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.6668\n",
      "Epoch 292/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.6712\n",
      "Epoch 293/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.6706\n",
      "Epoch 294/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.6679\n",
      "Epoch 295/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6674\n",
      "Epoch 296/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.6697\n",
      "Epoch 297/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.6659\n",
      "Epoch 298/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.6712\n",
      "Epoch 299/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4438 - accuracy: 0.6668\n",
      "Epoch 300/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6682\n",
      "Epoch 301/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.6709\n",
      "Epoch 302/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6685\n",
      "Epoch 303/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6700\n",
      "Epoch 304/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.6685\n",
      "Epoch 305/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.6676\n",
      "Epoch 306/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.6694\n",
      "Epoch 307/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4433 - accuracy: 0.6688\n",
      "Epoch 308/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.6729\n",
      "Epoch 309/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.6682\n",
      "Epoch 310/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.6665\n",
      "Epoch 311/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.6685\n",
      "Epoch 312/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.6697\n",
      "Epoch 313/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.6700\n",
      "Epoch 314/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.6668\n",
      "Epoch 315/400\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6688\n",
      "Epoch 316/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.6685\n",
      "Epoch 317/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.6659\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.6723\n",
      "Epoch 319/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.6674\n",
      "Epoch 320/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.6709\n",
      "Epoch 321/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.6659\n",
      "Epoch 322/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.6676\n",
      "Epoch 323/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4427 - accuracy: 0.6691\n",
      "Epoch 324/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.6647\n",
      "Epoch 325/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.6668\n",
      "Epoch 326/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.6679\n",
      "Epoch 327/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.6703\n",
      "Epoch 328/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6685\n",
      "Epoch 329/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.6691\n",
      "Epoch 330/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.6679\n",
      "Epoch 331/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.6668\n",
      "Epoch 332/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.6668\n",
      "Epoch 333/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4421 - accuracy: 0.6668\n",
      "Epoch 334/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.6723\n",
      "Epoch 335/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.6674\n",
      "Epoch 336/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.6709\n",
      "Epoch 337/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.6647\n",
      "Epoch 338/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4420 - accuracy: 0.6685\n",
      "Epoch 339/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.6744\n",
      "Epoch 340/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.6709\n",
      "Epoch 341/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.6703\n",
      "Epoch 342/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.6726\n",
      "Epoch 343/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.6676\n",
      "Epoch 344/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.6671\n",
      "Epoch 345/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.6709\n",
      "Epoch 346/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.6679\n",
      "Epoch 347/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.6635\n",
      "Epoch 348/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.6720\n",
      "Epoch 349/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4416 - accuracy: 0.6685\n",
      "Epoch 350/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4420 - accuracy: 0.6688\n",
      "Epoch 351/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4422 - accuracy: 0.6697\n",
      "Epoch 352/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4418 - accuracy: 0.6717\n",
      "Epoch 353/400\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.4417 - accuracy: 0.6735\n",
      "Epoch 354/400\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 0.4418 - accuracy: 0.6694\n",
      "Epoch 355/400\n",
      "107/107 [==============================] - 2s 20ms/step - loss: 0.4420 - accuracy: 0.6656\n",
      "Epoch 356/400\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 0.4416 - accuracy: 0.6703\n",
      "Epoch 357/400\n",
      "107/107 [==============================] - 2s 18ms/step - loss: 0.4412 - accuracy: 0.6717\n",
      "Epoch 358/400\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 0.4418 - accuracy: 0.6653\n",
      "Epoch 359/400\n",
      "107/107 [==============================] - 2s 17ms/step - loss: 0.4419 - accuracy: 0.6700\n",
      "Epoch 360/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4414 - accuracy: 0.6709\n",
      "Epoch 361/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4416 - accuracy: 0.6735\n",
      "Epoch 362/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4417 - accuracy: 0.6688\n",
      "Epoch 363/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4416 - accuracy: 0.6676\n",
      "Epoch 364/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4419 - accuracy: 0.6685\n",
      "Epoch 365/400\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 0.4414 - accuracy: 0.6703\n",
      "Epoch 366/400\n",
      "107/107 [==============================] - 2s 15ms/step - loss: 0.4418 - accuracy: 0.6700\n",
      "Epoch 367/400\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.4412 - accuracy: 0.6682\n",
      "Epoch 368/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.6691\n",
      "Epoch 369/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.6712\n",
      "Epoch 370/400\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.4416 - accuracy: 0.6715\n",
      "Epoch 371/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4413 - accuracy: 0.6723\n",
      "Epoch 372/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.6668\n",
      "Epoch 373/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.6688\n",
      "Epoch 374/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.6703\n",
      "Epoch 375/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4409 - accuracy: 0.6723\n",
      "Epoch 376/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.6676\n",
      "Epoch 377/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4411 - accuracy: 0.6720\n",
      "Epoch 378/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4416 - accuracy: 0.6697\n",
      "Epoch 379/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4411 - accuracy: 0.6697\n",
      "Epoch 380/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4415 - accuracy: 0.6694\n",
      "Epoch 381/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.6744\n",
      "Epoch 382/400\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.6685\n",
      "Epoch 383/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4410 - accuracy: 0.6709\n",
      "Epoch 384/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4413 - accuracy: 0.6706\n",
      "Epoch 385/400\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.6671\n",
      "Epoch 386/400\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.4406 - accuracy: 0.6717\n",
      "Epoch 387/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4405 - accuracy: 0.6723\n",
      "Epoch 388/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.6715\n",
      "Epoch 389/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4409 - accuracy: 0.6712\n",
      "Epoch 390/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.6715\n",
      "Epoch 391/400\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.6700\n",
      "Epoch 392/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4404 - accuracy: 0.6691\n",
      "Epoch 393/400\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.4404 - accuracy: 0.6709\n",
      "Epoch 394/400\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.6732\n",
      "Epoch 395/400\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.4402 - accuracy: 0.6726\n",
      "Epoch 396/400\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.6712\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 6ms/step - loss: 0.4402 - accuracy: 0.6706\n",
      "Epoch 398/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.6735\n",
      "Epoch 399/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.6712\n",
      "Epoch 400/400\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.6691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83d6d5ff70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model2 = tf.keras.models.Sequential()\n",
    "nn_model2.add(tf.keras.layers.Dense(units=9, activation=\"relu\", input_dim=9))\n",
    "nn_model2.add(tf.keras.layers.Dense(units=9, activation=\"relu\"))\n",
    "#nn_model2.add(tf.keras.layers.Dense(units=11, activation=\"relu\"))\n",
    "\n",
    "nn_model2.add(tf.keras.layers.Dense(units=3, activation=\"sigmoid\"))\n",
    "nn_model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "nn_model2.fit(X_train_scaled, y_train, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8256c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 0s - loss: 0.4616 - accuracy: 0.6547 - 349ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4616198241710663, 0.6546573042869568]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model2.evaluate(X_test_scaled,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ff8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_model2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d75c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nn_model2, open('nn_model.pkl','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141972b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad2264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
